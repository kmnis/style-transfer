{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d09a65-6294-468d-b427-048c81736075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import dnnlib\n",
    "import torch_utils\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c20a457-22d5-4ee6-81c7-c12290e45d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(path):\n",
    "  with open(path, 'rb') as f:\n",
    "    _G = pickle.load(f)['G_ema'].cuda()\n",
    "  return _G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800e8681-a958-4fdc-a9e1-3b473018230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-11 14:22:55--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/stylegan2-ffhq-256x256.pkl\n",
      "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.43.80.231, 44.236.229.128\n",
      "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.43.80.231|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan2/versions/1/files/stylegan2-ffhq-256x256.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan2-ffhq-256x256.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230811T142255Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=AKIA3PSNVSIZ42OUKYPX%2F20230811%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=ed6c5502902c773826e8c664b6356228611d33ffe197149df8c4a23343946139 [following]\n",
      "--2023-08-11 14:22:55--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/research/models/stylegan2/versions/1/files/stylegan2-ffhq-256x256.pkl?response-content-disposition=attachment%3B%20filename%3D%22stylegan2-ffhq-256x256.pkl%22&response-content-type=application%2Foctet-stream&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230811T142255Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=AKIA3PSNVSIZ42OUKYPX%2F20230811%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=ed6c5502902c773826e8c664b6356228611d33ffe197149df8c4a23343946139\n",
      "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 3.5.78.135, 52.92.129.98, 52.218.244.97, ...\n",
      "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|3.5.78.135|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 295726832 (282M) [application/octet-stream]\n",
      "Saving to: ‘stylegan2-ffhq-256x256.pkl’\n",
      "\n",
      "stylegan2-ffhq-256x 100%[===================>] 282.03M  18.4MB/s    in 16s     \n",
      "\n",
      "2023-08-11 14:23:12 (17.3 MB/s) - ‘stylegan2-ffhq-256x256.pkl’ saved [295726832/295726832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "init_model = 'stylegan2-ffhq-256x256.pkl'\n",
    "\n",
    "!wget https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan2/versions/1/files/{init_model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4cb461-42e5-445c-8508-e60f15d96fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_raw = 'stylegan2-ffhq-256x256.pkl'\n",
    "G =  get_model(net_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0db24-a2a2-43b0-bf7e-5264653f5ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec08eb7-e924-4c20-b0bb-66ace503a3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['G', 'D', 'G_ema', 'training_set_kwargs', 'augment_pipe', 'kwargs'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43cfd949-cbd3-4313-8a18-cb20ace4c6f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m net_tuned \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../localtoon/source/stylegan2/face_generation/experiment_stylegan/ffhq_style_s256/models/000400.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m G_new \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(G)\n\u001b[0;32m----> 4\u001b[0m G_tuned \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_tuned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mg_ema\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "net_tuned = '../localtoon/source/stylegan2/face_generation/experiment_stylegan/ffhq_style_s256/models/000400.pt'\n",
    "\n",
    "G_new = copy.deepcopy(G)\n",
    "G_tuned = torch.load(net_tuned)['g_ema'].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e3a7595-1bb0-4246-9736-3b1ebeb122f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'synthesis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m       newDictSynt[key] \u001b[38;5;241m=\u001b[39m newDictSynt[key]\u001b[38;5;241m*\u001b[39ml \u001b[38;5;241m+\u001b[39m G\u001b[38;5;241m.\u001b[39msynthesis\u001b[38;5;241m.\u001b[39mstate_dict()[key]\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39ml)\n\u001b[1;32m     22\u001b[0m   G_new\u001b[38;5;241m.\u001b[39msynthesis\u001b[38;5;241m.\u001b[39mload_state_dict(newDictSynt)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mdoBlend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mdoBlend\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdoBlend\u001b[39m(): \n\u001b[0;32m---> 13\u001b[0m   newDictSynt \u001b[38;5;241m=\u001b[39m \u001b[43mG_tuned\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynthesis\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     14\u001b[0m   GSyntKeys \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39msynthesis\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m GSyntKeys:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'synthesis'"
     ]
    }
   ],
   "source": [
    "blend = {\n",
    "    '4':0,\n",
    "    '8':0,\n",
    "    '16':0,\n",
    "    '32':0,\n",
    "    '64':0.5,\n",
    "    '128':1,\n",
    "    '256':0.7,\n",
    "} #main\n",
    "\n",
    "\n",
    "def doBlend(): \n",
    "  newDictSynt = G_tuned.synthesis.state_dict().copy()\n",
    "  GSyntKeys = G.synthesis.state_dict().keys()\n",
    "\n",
    "  for key in GSyntKeys:\n",
    "    if key[:1]!='b': continue\n",
    "    if 'conv'in key:\n",
    "      l = blend[key.split('.')[0][1:]]\n",
    "      newDictSynt[key] = newDictSynt[key]*l + G.synthesis.state_dict()[key]*(1-l)\n",
    "\n",
    "  G_new.synthesis.load_state_dict(newDictSynt)\n",
    "doBlend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9126e2-3855-4cce-a7fb-92c8d9283029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['b4.const', 'b4.resample_filter', 'b4.conv1.weight', 'b4.conv1.noise_strength', 'b4.conv1.bias', 'b4.conv1.resample_filter', 'b4.conv1.noise_const', 'b4.conv1.affine.weight', 'b4.conv1.affine.bias', 'b4.torgb.weight', 'b4.torgb.bias', 'b4.torgb.affine.weight', 'b4.torgb.affine.bias', 'b8.resample_filter', 'b8.conv0.weight', 'b8.conv0.noise_strength', 'b8.conv0.bias', 'b8.conv0.resample_filter', 'b8.conv0.noise_const', 'b8.conv0.affine.weight', 'b8.conv0.affine.bias', 'b8.conv1.weight', 'b8.conv1.noise_strength', 'b8.conv1.bias', 'b8.conv1.resample_filter', 'b8.conv1.noise_const', 'b8.conv1.affine.weight', 'b8.conv1.affine.bias', 'b8.torgb.weight', 'b8.torgb.bias', 'b8.torgb.affine.weight', 'b8.torgb.affine.bias', 'b16.resample_filter', 'b16.conv0.weight', 'b16.conv0.noise_strength', 'b16.conv0.bias', 'b16.conv0.resample_filter', 'b16.conv0.noise_const', 'b16.conv0.affine.weight', 'b16.conv0.affine.bias', 'b16.conv1.weight', 'b16.conv1.noise_strength', 'b16.conv1.bias', 'b16.conv1.resample_filter', 'b16.conv1.noise_const', 'b16.conv1.affine.weight', 'b16.conv1.affine.bias', 'b16.torgb.weight', 'b16.torgb.bias', 'b16.torgb.affine.weight', 'b16.torgb.affine.bias', 'b32.resample_filter', 'b32.conv0.weight', 'b32.conv0.noise_strength', 'b32.conv0.bias', 'b32.conv0.resample_filter', 'b32.conv0.noise_const', 'b32.conv0.affine.weight', 'b32.conv0.affine.bias', 'b32.conv1.weight', 'b32.conv1.noise_strength', 'b32.conv1.bias', 'b32.conv1.resample_filter', 'b32.conv1.noise_const', 'b32.conv1.affine.weight', 'b32.conv1.affine.bias', 'b32.torgb.weight', 'b32.torgb.bias', 'b32.torgb.affine.weight', 'b32.torgb.affine.bias', 'b64.resample_filter', 'b64.conv0.weight', 'b64.conv0.noise_strength', 'b64.conv0.bias', 'b64.conv0.resample_filter', 'b64.conv0.noise_const', 'b64.conv0.affine.weight', 'b64.conv0.affine.bias', 'b64.conv1.weight', 'b64.conv1.noise_strength', 'b64.conv1.bias', 'b64.conv1.resample_filter', 'b64.conv1.noise_const', 'b64.conv1.affine.weight', 'b64.conv1.affine.bias', 'b64.torgb.weight', 'b64.torgb.bias', 'b64.torgb.affine.weight', 'b64.torgb.affine.bias', 'b128.resample_filter', 'b128.conv0.weight', 'b128.conv0.noise_strength', 'b128.conv0.bias', 'b128.conv0.resample_filter', 'b128.conv0.noise_const', 'b128.conv0.affine.weight', 'b128.conv0.affine.bias', 'b128.conv1.weight', 'b128.conv1.noise_strength', 'b128.conv1.bias', 'b128.conv1.resample_filter', 'b128.conv1.noise_const', 'b128.conv1.affine.weight', 'b128.conv1.affine.bias', 'b128.torgb.weight', 'b128.torgb.bias', 'b128.torgb.affine.weight', 'b128.torgb.affine.bias', 'b256.resample_filter', 'b256.conv0.weight', 'b256.conv0.noise_strength', 'b256.conv0.bias', 'b256.conv0.resample_filter', 'b256.conv0.noise_const', 'b256.conv0.affine.weight', 'b256.conv0.affine.bias', 'b256.conv1.weight', 'b256.conv1.noise_strength', 'b256.conv1.bias', 'b256.conv1.resample_filter', 'b256.conv1.noise_const', 'b256.conv1.affine.weight', 'b256.conv1.affine.bias', 'b256.torgb.weight', 'b256.torgb.bias', 'b256.torgb.affine.weight', 'b256.torgb.affine.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.synthesis.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0937e8ee-427d-4c6a-930d-794e057d3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.load(\"../localtoon/source/stylegan2/face_generation/experiment_stylegan/ffhq_style_s256/models_blend/G_blend_001000_4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667d1fbf-6c50-4487-a805-b3abaf70d9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['g_ema'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8763ffb-5c64-4dfb-a50d-5f67238488ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load(\"../localtoon/source/stylegan2/pretrained_models/stylegan2-ffhq-config-f-256-550000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0580ce1-0800-4a4b-a2e1-08c150c17180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['g', 'd', 'g_ema', 'g_optim', 'd_optim'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af9e770-c9d7-427a-aa53-e4960a4364f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['style.1.weight', 'style.1.bias', 'style.2.weight', 'style.2.bias', 'style.3.weight', 'style.3.bias', 'style.4.weight', 'style.4.bias', 'style.5.weight', 'style.5.bias', 'style.6.weight', 'style.6.bias', 'style.7.weight', 'style.7.bias', 'style.8.weight', 'style.8.bias', 'input.input', 'conv1.conv.weight', 'conv1.conv.modulation.weight', 'conv1.conv.modulation.bias', 'conv1.noise.weight', 'conv1.activate.bias', 'to_rgb1.bias', 'to_rgb1.conv.weight', 'to_rgb1.conv.modulation.weight', 'to_rgb1.conv.modulation.bias', 'convs.0.conv.weight', 'convs.0.conv.blur.kernel', 'convs.0.conv.modulation.weight', 'convs.0.conv.modulation.bias', 'convs.0.noise.weight', 'convs.0.activate.bias', 'convs.1.conv.weight', 'convs.1.conv.modulation.weight', 'convs.1.conv.modulation.bias', 'convs.1.noise.weight', 'convs.1.activate.bias', 'convs.2.conv.weight', 'convs.2.conv.blur.kernel', 'convs.2.conv.modulation.weight', 'convs.2.conv.modulation.bias', 'convs.2.noise.weight', 'convs.2.activate.bias', 'convs.3.conv.weight', 'convs.3.conv.modulation.weight', 'convs.3.conv.modulation.bias', 'convs.3.noise.weight', 'convs.3.activate.bias', 'convs.4.conv.weight', 'convs.4.conv.blur.kernel', 'convs.4.conv.modulation.weight', 'convs.4.conv.modulation.bias', 'convs.4.noise.weight', 'convs.4.activate.bias', 'convs.5.conv.weight', 'convs.5.conv.modulation.weight', 'convs.5.conv.modulation.bias', 'convs.5.noise.weight', 'convs.5.activate.bias', 'convs.6.conv.weight', 'convs.6.conv.blur.kernel', 'convs.6.conv.modulation.weight', 'convs.6.conv.modulation.bias', 'convs.6.noise.weight', 'convs.6.activate.bias', 'convs.7.conv.weight', 'convs.7.conv.modulation.weight', 'convs.7.conv.modulation.bias', 'convs.7.noise.weight', 'convs.7.activate.bias', 'convs.8.conv.weight', 'convs.8.conv.blur.kernel', 'convs.8.conv.modulation.weight', 'convs.8.conv.modulation.bias', 'convs.8.noise.weight', 'convs.8.activate.bias', 'convs.9.conv.weight', 'convs.9.conv.modulation.weight', 'convs.9.conv.modulation.bias', 'convs.9.noise.weight', 'convs.9.activate.bias', 'convs.10.conv.weight', 'convs.10.conv.blur.kernel', 'convs.10.conv.modulation.weight', 'convs.10.conv.modulation.bias', 'convs.10.noise.weight', 'convs.10.activate.bias', 'convs.11.conv.weight', 'convs.11.conv.modulation.weight', 'convs.11.conv.modulation.bias', 'convs.11.noise.weight', 'convs.11.activate.bias', 'to_rgbs.0.bias', 'to_rgbs.0.upsample.kernel', 'to_rgbs.0.conv.weight', 'to_rgbs.0.conv.modulation.weight', 'to_rgbs.0.conv.modulation.bias', 'to_rgbs.1.bias', 'to_rgbs.1.upsample.kernel', 'to_rgbs.1.conv.weight', 'to_rgbs.1.conv.modulation.weight', 'to_rgbs.1.conv.modulation.bias', 'to_rgbs.2.bias', 'to_rgbs.2.upsample.kernel', 'to_rgbs.2.conv.weight', 'to_rgbs.2.conv.modulation.weight', 'to_rgbs.2.conv.modulation.bias', 'to_rgbs.3.bias', 'to_rgbs.3.upsample.kernel', 'to_rgbs.3.conv.weight', 'to_rgbs.3.conv.modulation.weight', 'to_rgbs.3.conv.modulation.bias', 'to_rgbs.4.bias', 'to_rgbs.4.upsample.kernel', 'to_rgbs.4.conv.weight', 'to_rgbs.4.conv.modulation.weight', 'to_rgbs.4.conv.modulation.bias', 'to_rgbs.5.bias', 'to_rgbs.5.upsample.kernel', 'to_rgbs.5.conv.weight', 'to_rgbs.5.conv.modulation.weight', 'to_rgbs.5.conv.modulation.bias'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m['g'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d724e242-e730-4d7c-9ed0-5074091d6ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MappingNetwork(\n",
       "  z_dim=512, c_dim=0, w_dim=512, num_ws=14\n",
       "  (fc0): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  (fc1): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  (fc2): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  (fc3): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  (fc4): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  (fc5): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  (fc6): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       "  (fc7): FullyConnectedLayer(in_features=512, out_features=512, activation=lrelu)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa25ec8-3764-4df2-9a37-f489b472bf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.z_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4efa273-460f-469a-82a1-df77b85edacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5084081-4865-4ff5-8523-e3d8426341ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = np.random.RandomState(0)\n",
    "z = torch.tensor(rnd.randn(1, G.z_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8775320a-07ce-4911-bb04-82c66ddc68a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c0606-edd5-4932-90b1-659559c4f949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
